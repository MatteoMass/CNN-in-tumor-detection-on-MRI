{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET-gridsearch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y6X_WBXe2OS"
      },
      "outputs": [],
      "source": [
        "# Seed value\n",
        "seed_value= 0\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ISPR/modules/')\n",
        "from metrics import dice_coef\n",
        "from Unet import getUnetModel\n",
        "from losses import dice_loss, tversky_Loss"
      ],
      "metadata": {
        "id": "jlJaHw12fTjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data\n"
      ],
      "metadata": {
        "id": "uzx8riCki6oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "AbdLOlQFfzkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 256\n",
        "image_dataset = []\n",
        "mask_dataset = []\n",
        "\n",
        "image_directory = \"/content/drive/MyDrive/ISPR/immagini_x_\"+str(SIZE)+\"/\"\n",
        "mask_directory = \"/content/drive/MyDrive/ISPR/immagini_y_\"+str(SIZE)+\"/\""
      ],
      "metadata": {
        "id": "TAtgxbCQjDpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Images\n",
        "images = os.listdir(image_directory)\n",
        "images.sort()\n",
        "for i, image_name in enumerate(images): \n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = cv2.imread(image_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        image_dataset.append(np.array(image))\n",
        "\n",
        "#Masks\n",
        "masks = os.listdir(mask_directory)\n",
        "masks.sort()\n",
        "for i, image_name in enumerate(masks):\n",
        "    if (image_name.split('.')[1] == 'jpg' ):\n",
        "        image = cv2.imread(mask_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        mask_dataset.append(np.array(image))"
      ],
      "metadata": {
        "id": "wZpn0S2hjFsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Expand the dimension of the image dataset to include also the number of channels\n",
        "image_dataset = np.expand_dims(image_dataset,3)\n",
        "#Expand the dimension of the mask dataset to include also the number of channels\n",
        "#and threshold the data to obtain feasible masks\n",
        "mask_dataset = np.clip(np.expand_dims((np.array(mask_dataset)),3) - 200.0,0,1)"
      ],
      "metadata": {
        "id": "bOUxvyRpjUlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.1, random_state = 0)"
      ],
      "metadata": {
        "id": "e6BPz_pQkEJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample data\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(image_dataset[image_number], (SIZE, SIZE)), cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(mask_dataset[image_number], (SIZE, SIZE)), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SXFU0fSfkKKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "SVx4h2K0kpBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = [64, 128, 256, 512]\n",
        "#path = [32, 64, 128,256]\n",
        "bridge = 1024\n",
        "#bridge = 512\n",
        "#dropout = 0\n",
        "dropout = 0.1\n",
        "#loss = dice_loss\n",
        "#loss = tversky_Loss\n",
        "loss = 'binary_crossentropy'\n",
        "\n",
        "\n",
        "model = getUnetModel(SIZE, path, bridge, dropout, loss)"
      ],
      "metadata": {
        "id": "4720Ec2hkol1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=20,  \n",
        "                    validation_split  = 0.1,\n",
        "                    shuffle=False)\n"
      ],
      "metadata": {
        "id": "1s25Ommuk8zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plots"
      ],
      "metadata": {
        "id": "k0Nm22IClZZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "FHcoi7Jclhl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Accuracy\n",
        "fig, ax = plt.subplots()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "ax.set_xticks([0, 4, 9, 14, 19])\n",
        "ax.set_xticklabels(['1', '5', '10', '15' , '20'])\n",
        "\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pt8_J6P1ohOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Dice Coefficient\n",
        "fig, ax = plt.subplots()\n",
        "plt.plot(history.history['dice_coef'])\n",
        "plt.plot(history.history['val_dice_coef'])\n",
        "plt.title('Model Dice Coefficient')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "ax.set_xticks([0, 4, 9, 14, 19])\n",
        "ax.set_xticklabels(['1', '5', '10', '15' , '20'])\n",
        "\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NvAfNYg8oijN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Loss\n",
        "fig, ax = plt.subplots()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "ax.set_xticks([0, 4, 9, 14, 19])\n",
        "ax.set_xticklabels(['1', '5', '10', '15' , '20'])\n",
        "\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B_aLuSBWokDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test trained model\n",
        "image_number = random.randint(0, len(X_test))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(131)\n",
        "plt.imshow(np.reshape(X_test[image_number], (SIZE, SIZE)), cmap='gray')\n",
        "plt.subplot(132)\n",
        "plt.imshow(np.reshape(y_test[image_number], (SIZE, SIZE)), cmap='gray')\n",
        "plt.subplot(133)\n",
        "pred = model.predict(X_test[image_number].reshape(1,SIZE,SIZE,1))\n",
        "pred[pred >= 0.5] = 1\n",
        "pred[pred < 0.5] = 0\n",
        "plt.imshow(np.reshape(pred, (SIZE, SIZE)), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9U-f12G5BWIc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}